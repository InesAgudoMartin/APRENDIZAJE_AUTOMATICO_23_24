{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOPLNW90TTLcT1+1IykxJT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InesAgudoMartin/APRENDIZAJE_AUTOMATICO_23_24/blob/main/GUARDADOPROCESAMIENTO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "PRÁCTICA II: PROCESAMIENTO DE VÍDEO"
      ],
      "metadata": {
        "id": "TOE1owLdtSQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTRODUCCIÓN:"
      ],
      "metadata": {
        "id": "0_BVcPAetUhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFIGURACIÓN DEL ENTORNO"
      ],
      "metadata": {
        "id": "dYrphZrFtWP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuramos las herramientas necesarias para cargar, procesar, visualizar y analizar videos e imágenes en Colab."
      ],
      "metadata": {
        "id": "etEwx6IetX7x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es3DTKWjtNe7"
      },
      "outputs": [],
      "source": [
        "# Importamos bibliotecas\n",
        "import cv2  #imágenes y vídeos\n",
        "import numpy as np  #operaciones\n",
        "import matplotlib.pyplot as plt  #visualización\n",
        "from google.colab.patches import cv2_imshow #mostrar imágenes en colab\n",
        "import time  #pausas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cuánto a las bibliotecas utilizadas:\n",
        "\n",
        "matplotlib.pyplot la hemos añadido para visualizar imágenes o gráficos dentro de Colab.\n",
        "\n",
        "cv2_imshow, se trata de una versión adaptada de cv2.imshow, para mostrar imágenes en Colab, para el apartado en el que mostramos las 5 primeras imágenes del vídeo, es una manera de entender mejor la secuencia, tener más datos y poder ubicarnos al principio para el análisis posterior. Esta función implementada nos permite visualizar los 5 primeros fotogrmas de esta secuencia con la que trabajamos.\n",
        "\n",
        "Por otro lado, hemos usado esta que es menos común, time para controlar pausas en la ejecución, es decir, refiriéndonos al mismo apartado del que hablábamos antes, para visualizar las primeras fotos, cuando queremos esperar entre una y otra."
      ],
      "metadata": {
        "id": "Akewj0j8tbWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPENCV\n",
        "\n",
        "OpenCV (Open Source Computer Vision Library) es una biblioteca diseñada para aplicaciones de procesamiento de imágenes y videos. Nos permite trabajar de manera sencilla con imágenes, videos, y aplciar ciertas técnicas como detección de objetos, seguimiento...\n",
        "\n",
        "En esta práctica en concreto la utilizamos porque estamos trabajando con procesamiento de vídeo y nos permite leer videos desde archivos, modificar cada fotograma del vídeo (aplicar filtros, detectar bordes...), incluso guardar los vídeos en distintos formatos. Por otro lado, a la hora de aplicar técnicas que es en parte, de lo que se trata esta práctica, esta biblioteca permite aplicar muchas de ellas como:\n",
        "\n",
        "Detección de bordes Segmentación Seguimiento de objetos En el primero paso de cargar o preparar el vídeo, hemos utilizado funciones como cv2.VideoCapture para cargar el video y cv2.VideoWriter para guardar los resultados procesados.\n",
        "\n",
        "Además, import cv2 lo usamos para cargar la biblioteca de OpenCV en el código. Una vez importada, podemos usar todas sus funciones para trabajar con imágenes y videos."
      ],
      "metadata": {
        "id": "nq-XNmaQtdUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARACIÓN DEL VÍDEO\n",
        "En este primer paso, hemos seleccionado un video en formato MP4 (como pide el enunciado), que dura más de 10 segundos y con un contenido lo suficientemente adecuado para poder aplicar técnicas de procesamiento. Hemos cargado el video en el entorno de Colab, y hemos comprobado sus propiedades que es importante tenerlas en cuenta a la hora de realizar el proyecto."
      ],
      "metadata": {
        "id": "WCLCaG4_tf8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '6640000-hd_1920_1080_25fps.mp4'\n",
        "\n",
        "#Cargamos el video con OpenCV\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# propiedades\n",
        "if not cap.isOpened():\n",
        "    print(\"Error al abrir video.\")\n",
        "else:\n",
        "    print(\"Video cargado correctamente.\")\n",
        "    print(f\"Resolución: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}\") #devuelve el alto y ancho del video\n",
        "    print(f\"FPS: {cap.get(cv2.CAP_PROP_FPS)}\")\n",
        "    #devuelve numero total de fotografías en el vídeo\n",
        "    print(f\"Duración: {int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS))} segundos\")\n",
        "\n",
        "\n",
        "    #visualizar las 5 primeras imágenes\n",
        "    for i in range(5):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Error al leer fotograma.\")\n",
        "            break\n",
        "        cv2_imshow(frame)\n",
        "        time.sleep(0.5)  # 0.5s entre fotogramas\n",
        "\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "NXK6OMEptij6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo en cuenta los resultados obtenidos, que parecen típicos, algo que ya sabemos o que simplemente contienen todos los vídeos, pero es realmente importante conocer a qué se refiere o para qué nos sirve cada una de las propiedades de cara al análisis posterior.\n",
        "\n",
        "En cuánto a la duración, que son 34s, nos indica el tiempo total que estará el vídeo en reproducción. Se considera buena ya que si fuese demasiado corto podría no proporcionar suficientes fotografías (recordamos que el vídeo es una secuencia de fotogramas) para aplicar las técnicas, mientras que uno muy largo resultaría incluso costoso de analizar. La duración de un vídeo consiste en el número total de fotogramas entre los fotogramas por segundo (FPS).\n",
        "\n",
        "También hemos visto que tiene una resolución de 1920x1080, que es el tamaño del vídeo en píxeles: en este caso 1920 de ancho y 1080 de alto. Una resolución mucho más alta aunque nos daría más información visual y sería más fácil para aplicar características como detección de bordes, podría ralentizar el procesamiento porque necesita más datos por fotograma.\n",
        "\n",
        "Como hemos nombrado antes, los FPS o fotogramas por segundo en este vídeo son 25, se refieren a las imágenes individuales que componen un segundo del vídeo (cada segundo esta compuesto por 25 imágenes). Un FPS alto permite un movimiento más fluido, que nos podría interesar para técnicas como el seguimiento de objetos, porque no habrá \"saltos\" bruscos entre fotogramas."
      ],
      "metadata": {
        "id": "ceQbn85etlM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTERFAZ"
      ],
      "metadata": {
        "id": "1yjesRyotqeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necesarias\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Ruta del video predefinida\n",
        "video_path = '6640000-hd_1920_1080_25fps.mp4'\n",
        "\n",
        "# Función para mostrar las opciones de procesamiento\n",
        "def mostrar_menu():\n",
        "    print(\"\\nOpciones de procesamiento:\")\n",
        "    print(\"1. Detección de bordes\")\n",
        "    print(\"2. Segmentación\")\n",
        "    print(\"3. Seguimiento de objetos\")\n",
        "    print(\"4. Salir\")\n",
        "\n",
        "# Función principal para la interfaz\n",
        "def interfaz_usuario():\n",
        "    # Mostrar mensaje de bienvenida\n",
        "    print(\"Bienvenido al sistema de procesamiento de video.\\n\")\n",
        "\n",
        "    # Verificar si el archivo existe\n",
        "    if not os.path.isfile(video_path):\n",
        "        print(\"Error: El archivo no existe o la ruta es incorrecta.\")\n",
        "        return\n",
        "\n",
        "    # Intentar cargar el video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error al abrir el video. Verifica que el archivo sea válido.\")\n",
        "        return\n",
        "\n",
        "    print(\"Video cargado correctamente.\")\n",
        "    print(f\"Resolución: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}\")\n",
        "    print(f\"FPS: {cap.get(cv2.CAP_PROP_FPS)}\")\n",
        "    print(f\"Duración: {int(cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS))} segundos\")\n",
        "\n",
        "    # Mostrar opciones de procesamiento\n",
        "    while True:\n",
        "        mostrar_menu()\n",
        "        opcion = input(\"Selecciona una opción de procesamiento (1-4): \")\n",
        "\n",
        "        if opcion == '1':\n",
        "            print(\"Has seleccionado: Detección de bordes.\")\n",
        "            # Aquí iría la función para detección de bordes\n",
        "        elif opcion == '2':\n",
        "            print(\"Has seleccionado: Segmentación.\")\n",
        "            # Aquí iría la función para segmentación\n",
        "        elif opcion == '3':\n",
        "            print(\"Has seleccionado: Seguimiento de objetos.\")\n",
        "            # Aquí iría la función para seguimiento de objetos\n",
        "        elif opcion == '4':\n",
        "            print(\"Saliendo del programa. ¡Hasta luego!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Opción no válida. Por favor, selecciona una opción válida.\")\n",
        "\n",
        "    # Liberar recursos\n",
        "    cap.release()\n",
        "\n",
        "# Ejecutar la interfaz de usuario\n",
        "interfaz_usuario()\n",
        "\n"
      ],
      "metadata": {
        "id": "54Ap1beRtr4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "COhvT1bAtiJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Ruta del video\n",
        "video_path = '6640000-hd_1920_1080_25fps.mp4'\n",
        "\n",
        "# Función para detección de bordes (Canny)\n",
        "def detectar_bordes(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convertir a escala de grises\n",
        "    edges = cv2.Canny(gray, 100, 200)  # Aplicar el detector de bordes Canny\n",
        "    return edges\n",
        "\n",
        "# Función para segmentación del fondo\n",
        "def segmentar_fondo(frame, background_subtractor):\n",
        "    fg_mask = background_subtractor.apply(frame)  # Aplicar sustracción de fondo\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)  # Eliminar ruido\n",
        "    return fg_mask\n",
        "\n",
        "# Clase para el seguimiento de objetos\n",
        "class EuclideanDistTracker:\n",
        "    def __init__(self):\n",
        "        self.center_points = {}\n",
        "        self.id_count = 0\n",
        "\n",
        "    def update(self, objects_rect):\n",
        "        objects_bbs_ids = []\n",
        "        for rect in objects_rect:\n",
        "            x, y, w, h = rect\n",
        "            cx = (x + x + w) // 2\n",
        "            cy = (y + y + h) // 2\n",
        "\n",
        "            same_object_detected = False\n",
        "            for id, pt in self.center_points.items():\n",
        "                dist = np.hypot(cx - pt[0], cy - pt[1])\n",
        "                if dist < 25:\n",
        "                    self.center_points[id] = (cx, cy)\n",
        "                    objects_bbs_ids.append([x, y, w, h, id])\n",
        "                    same_object_detected = True\n",
        "                    break\n",
        "\n",
        "            if not same_object_detected:\n",
        "                self.center_points[self.id_count] = (cx, cy)\n",
        "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
        "                self.id_count += 1\n",
        "\n",
        "        self.center_points = {id: self.center_points[id] for _, _, _, _, id in objects_bbs_ids}\n",
        "        return objects_bbs_ids\n",
        "\n",
        "# Función principal para procesamiento de video\n",
        "def procesar_video(video_path):\n",
        "    # Crear objeto para sustracción de fondo\n",
        "    background_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "    # Crear tracker para seguimiento\n",
        "    tracker = EuclideanDistTracker()\n",
        "\n",
        "    # Cargar video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error al abrir el video.\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # 1. Aplicar detección de bordes\n",
        "        edges = detectar_bordes(frame)\n",
        "\n",
        "        # 2. Aplicar segmentación del fondo\n",
        "        fg_mask = segmentar_fondo(frame, background_subtractor)\n",
        "\n",
        "        # 3. Detección de contornos y seguimiento de objetos\n",
        "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        detections = []\n",
        "\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area > 100:  # Umbral mínimo de área\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "                detections.append([x, y, w, h])\n",
        "\n",
        "        boxes_ids = tracker.update(detections)\n",
        "\n",
        "        for box_id in boxes_ids:\n",
        "            x, y, w, h, obj_id = box_id\n",
        "            cv2.putText(frame, f\"ID: {obj_id}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "        # Mostrar resultados\n",
        "        cv2.imshow('Original', frame)\n",
        "        cv2.imshow('Bordes', edges)\n",
        "        cv2.imshow('Segmentación', fg_mask)\n",
        "\n",
        "        # Salir con la tecla 'q'\n",
        "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Ejecutar procesamiento\n",
        "procesar_video(video_path)\n"
      ],
      "metadata": {
        "id": "4xWwakmvv8Sj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}